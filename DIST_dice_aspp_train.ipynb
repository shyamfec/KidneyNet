{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_RCK1HN3DLQp"
   },
   "outputs": [],
   "source": [
    "## Importing necessary libraries\n",
    "\n",
    "import torch as tor\n",
    "import torch.nn as nn\n",
    "import torchvision as tv\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from dist_utils.nn_layers.cnn_utils import *\n",
    "import math\n",
    "import time\n",
    "from PIL import Image as im\n",
    "\n",
    "from sklearn.metrics import f1_score \n",
    "import dist_utils.postprocessing as pp\n",
    "from sklearn.metrics import jaccard_score \n",
    "import random\n",
    "\n",
    "import statistics as stats\n",
    "import copy\n",
    "\n",
    "import albumentations as A\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evbCiyI05tA5"
   },
   "outputs": [],
   "source": [
    "def calc_total_mean(datafiles,num_chn = 3,verbose = False):\n",
    "\n",
    "    \"\"\"\n",
    "        Function to calculate the mean of the training dataset \n",
    "        \n",
    "        Arguments:\n",
    "            datafiles : Directory of training dataset\n",
    "            num_chn   : The number of channels in each image : Default = 3 channels\n",
    "            verbose   : flag to print the ser. number and filename of each image\n",
    "            \n",
    "        Returns: \n",
    "            The mean image of the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    img_sum = 0\n",
    "    num_files = len(datafiles)\n",
    "\n",
    "    for e,file in enumerate(datafiles):\n",
    "\n",
    "        if(num_chn == 3):\n",
    "            img = cv2.resize(cv2.imread(file),(256,256))\n",
    "            img_sum += img\n",
    "        elif(num_chn == 1):\n",
    "            img = cv2.imread(file,0)\n",
    "            img_sum += img\n",
    "        else:\n",
    "            assert \"Incorrect number of channels\"\n",
    "\n",
    "        if(verbose):\n",
    "            print(e,file)\n",
    "\n",
    "\n",
    "    return np.float32(img_sum) / num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPeLz3De-nOZ"
   },
   "outputs": [],
   "source": [
    "class dice(nn.Module):\n",
    "    \"\"\"\n",
    "    This class implements the volume-wise seperable convolutions\n",
    "    \"\"\"\n",
    "    def __init__(self, channel_in, channel_out, height, width, kernel_size=3, dilation=[1, 1, 1], shuffle=True):\n",
    "        \n",
    "        \"\"\"\n",
    "            Constructor to initialize the DiCE block instance \n",
    "            \n",
    "            Arguements:\n",
    "                channel_in: Number of input channels\n",
    "                channel_out: Number of output channels\n",
    "                height: Height of the input volume\n",
    "                width: Width of the input volume\n",
    "                kernel_size: Size of the kernel\n",
    "                dilation: Rates of dilation for each dimension\n",
    "                shuffle: shuffling the feature maps\n",
    "                \n",
    "            Returns:\n",
    "                The convolution operation result performed by successive dimconv and dimfuse operations\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        assert len(dilation) == 3\n",
    "        padding_1 = int((kernel_size - 1) / 2) *dilation[0] \n",
    "        padding_2 = int((kernel_size - 1) / 2) *dilation[1] \n",
    "        padding_3 = int((kernel_size - 1) / 2) *dilation[2] \n",
    "        self.conv_channel = nn.Conv2d(channel_in, channel_in, kernel_size=kernel_size, stride=1, groups=channel_in,\n",
    "                                      padding=padding_1, bias=False, dilation=dilation[0])\n",
    "        self.conv_width = nn.Conv2d(width, width, kernel_size=kernel_size, stride=1, groups=width,\n",
    "                               padding=padding_2, bias=False, dilation=dilation[1])\n",
    "        self.conv_height = nn.Conv2d(height, height, kernel_size=kernel_size, stride=1, groups=height,\n",
    "                               padding=padding_3, bias=False, dilation=dilation[2])\n",
    "\n",
    "        self.br_act = BR(3*channel_in)\n",
    "        self.weight_avg_layer = CBR(3*channel_in, channel_in, kSize=1, stride=1, groups=channel_in)\n",
    "\n",
    "        # project from channel_in to Channel_out\n",
    "        groups_proj = math.gcd(channel_in, channel_out)\n",
    "        self.proj_layer = CBR(channel_in, channel_out, kSize=3, stride=1, groups=groups_proj)\n",
    "        self.linear_comb_layer = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=1),\n",
    "            nn.Conv2d(channel_in, channel_in // 4, kernel_size=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channel_in //4, channel_out, kernel_size=1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.vol_shuffle = Shuffle(3)\n",
    "\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.channel_in = channel_in\n",
    "        self.channel_out = channel_out\n",
    "        self.shuffle = shuffle\n",
    "        self.ksize=kernel_size\n",
    "        self.dilation = dilation\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "            Method that implements the forward operation of the DiCE block\n",
    "            \n",
    "            Arguments:\n",
    "                x: input to the DiCE block\n",
    "                \n",
    "            Returns:\n",
    "                convolution output\n",
    "        \"\"\"\n",
    "        \n",
    "        bsz, channels, height, width = x.size()\n",
    "        \n",
    "        # process across channel. Input: C x H x W, Output: C x H x W\n",
    "        out_ch_wise = self.conv_channel(x)\n",
    "\n",
    "        # process across height. Input: H x C x W, Output: C x H x W\n",
    "        x_h_wise = x.clone()\n",
    "        if height != self.height:\n",
    "            if height < self.height:\n",
    "                x_h_wise = F.interpolate(x_h_wise, mode='bilinear', size=(self.height, width), align_corners=True)\n",
    "            else:\n",
    "                x_h_wise = F.adaptive_avg_pool2d(x_h_wise, output_size=(self.height, width))\n",
    "\n",
    "        x_h_wise = x_h_wise.transpose(1, 2).contiguous()\n",
    "        out_h_wise = self.conv_height(x_h_wise).transpose(1, 2).contiguous()\n",
    "\n",
    "        h_wise_height = out_h_wise.size(2)\n",
    "        if height != h_wise_height:\n",
    "            if h_wise_height < height:\n",
    "                out_h_wise = F.interpolate(out_h_wise, mode='bilinear', size=(height, width), align_corners=True)\n",
    "            else:\n",
    "                out_h_wise = F.adaptive_avg_pool2d(out_h_wise, output_size=(height, width))\n",
    "\n",
    "        # process across width: Input: W x H x C, Output: C x H x W\n",
    "        x_w_wise = x.clone()\n",
    "        if width != self.width:\n",
    "            if width < self.width:\n",
    "                x_w_wise = F.interpolate(x_w_wise, mode='bilinear', size=(height, self.width), align_corners=True)\n",
    "            else:\n",
    "                x_w_wise = F.adaptive_avg_pool2d(x_w_wise, output_size=(height, self.width))\n",
    "\n",
    "        x_w_wise = x_w_wise.transpose(1, 3).contiguous()\n",
    "        out_w_wise = self.conv_width(x_w_wise).transpose(1, 3).contiguous()\n",
    "        w_wise_width = out_w_wise.size(3)\n",
    "        if width != w_wise_width:\n",
    "            if w_wise_width < width:\n",
    "                out_w_wise = F.interpolate(out_w_wise, mode='bilinear', size=(height, width), align_corners=True)\n",
    "            else:\n",
    "                out_w_wise = F.adaptive_avg_pool2d(out_w_wise, output_size=(height, width))\n",
    "\n",
    "        # Merge. Output will be 3C x H X W\n",
    "        outputs = torch.cat((out_ch_wise, out_h_wise, out_w_wise), 1)\n",
    "        outputs = self.br_act(outputs)\n",
    "\n",
    "        if self.shuffle:\n",
    "            outputs = self.vol_shuffle(outputs)\n",
    "        outputs = self.weight_avg_layer(outputs)\n",
    "        linear_wts = self.linear_comb_layer(outputs)\n",
    "        proj_out = self.proj_layer(outputs)\n",
    "        return proj_out * linear_wts\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = '{name}(in_channels={channel_in}, out_channels={channel_out}, kernel_size={ksize}, vol_shuffle={shuffle}, ' \\\n",
    "            'width={width}, height={height}, dilation={dilation})'\n",
    "        return s.format(name=self.__class__.__name__, **self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tALktTzvn9Zb"
   },
   "outputs": [],
   "source": [
    "class aspp_dice(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        Module that implements the ASPP block and standard convolutions replaced by dimension-wise convolutions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,in_channels,mid_channels,prev_dim,rates):\n",
    "\n",
    "        \"\"\"\n",
    "            Constructor to initialize the ASPP_DiCE block instance\n",
    "            \n",
    "            Arguments:\n",
    "                in_channels   : The number of channels in the dense feature map after the encoder pipeline\n",
    "                mid_channels  : The number of feature maps to be output by each of the convolution blocks\n",
    "                prev_dim      : size of the input dense feature map after the encoder pipeline\n",
    "                rates         : Dilation rates of the three convolution blocks\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        r1,r2,r3 = rates\n",
    "\n",
    "        self.branch1 = dice(in_channels,mid_channels,height = 32,width = 32,kernel_size = 1)\n",
    "        self.branch2 = dice(in_channels,mid_channels,height = 32,width = 32,kernel_size = 3,dilation = [1,r1,r1])\n",
    "        self.branch3 = dice(in_channels,mid_channels,height = 32,width = 32,kernel_size = 3,dilation = [1,r2,r2])\n",
    "        self.branch4 = dice(in_channels,mid_channels,height = 32,width = 32,kernel_size = 3,dilation = [1,r3,r3])\n",
    "        self.branch5 = nn.AvgPool2d(kernel_size = prev_dim)\n",
    "\n",
    "        self.prev_dim = prev_dim\n",
    "\n",
    "        self.upsample = nn.UpsamplingBilinear2d(size = prev_dim)\n",
    "\n",
    "        self.final_layer = dice(mid_channels * 4 + in_channels,in_channels,height = 32,width = 32,kernel_size = 1)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        \"\"\"\n",
    "            Method to implement the forward pass of the ASPP_DiCE block\n",
    "            \n",
    "            Arguements: \n",
    "                x   : Input to the ASPP_DiCE block\n",
    "                \n",
    "            Returns: \n",
    "                out : Output of the ASPP_DiCE block\n",
    "        \"\"\"\n",
    "        \n",
    "        out1 = self.upsample(self.branch1(x))\n",
    "        out2 = self.upsample(self.branch2(x))\n",
    "        out3 = self.upsample(self.branch3(x))\n",
    "        out4 = self.upsample(self.branch4(x))\n",
    "        out5 = self.upsample(self.branch5(x))\n",
    "\n",
    "        out = tor.cat((out1,out2,out3,out4,out5),dim = 1)\n",
    "\n",
    "        out = self.final_layer(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aszx-Sh9E2Vb"
   },
   "outputs": [],
   "source": [
    "class dist_dice(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        Module that implements KidneyNet\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,in_channels,nfeat,mid_channels = 256):\n",
    "        \n",
    "        \"\"\"\n",
    "            Constructor to initialize the KidneyNet instance\n",
    "            \n",
    "            Arguments: \n",
    "                in_channels  : The number of channels of the input tissue image\n",
    "                nfeat        : Hyper-parameter that dictates the number of feature maps \n",
    "                mid_channels : The number of channels to be considered for the ASPP_DiCE block\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1a = nn.Conv2d(in_channels = in_channels,out_channels = nfeat,kernel_size = (3,3),padding = 1)\n",
    "        self.bn1a = nn.BatchNorm2d(nfeat)\n",
    "        self.conv1b = dice(nfeat,nfeat,height = 256,width = 256)\n",
    "        self.bn1b = nn.BatchNorm2d(nfeat)\n",
    "\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = (2,2), stride = 2)\n",
    "\n",
    "        self.conv2a = dice(nfeat,2 * nfeat,width = 128,height = 128)\n",
    "        self.bn2a = nn.BatchNorm2d(2 * nfeat)\n",
    "        self.conv2b = dice(2 * nfeat,2 * nfeat,width = 128,height = 128)\n",
    "        self.bn2b = nn.BatchNorm2d(2 * nfeat)\n",
    "\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = (2,2), stride = 2)\n",
    "\n",
    "        self.conv3a = dice(2 * nfeat,4 * nfeat,width = 64,height = 64)\n",
    "        self.bn3a = nn.BatchNorm2d(4 * nfeat)\n",
    "        self.conv3b = dice(4 * nfeat,4 * nfeat,width = 64,height = 64)\n",
    "        self.bn3b = nn.BatchNorm2d(4 * nfeat)\n",
    "\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = (2,2),stride = 2)\n",
    "\n",
    "        self.conv4a = dice(4 * nfeat,8 * nfeat,width = 32,height = 32)\n",
    "        self.bn4a = nn.BatchNorm2d(8 * nfeat)\n",
    "        self.conv4b = dice(8 * nfeat,8 * nfeat,width = 32,height = 32)\n",
    "        self.bn4b = nn.BatchNorm2d(8 * nfeat)\n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(in_channels = 8 * nfeat,out_channels = 4 * nfeat, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
    "\n",
    "        self.conv6a = dice(8 * nfeat,4 * nfeat,width = 64,height = 64)\n",
    "        self.bn6a = nn.BatchNorm2d(4 * nfeat)\n",
    "        self.conv6b = dice(4 * nfeat,4 * nfeat,width = 64,height = 64)\n",
    "        self.bn6b = nn.BatchNorm2d(4 * nfeat)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(in_channels = 4 * nfeat,out_channels = 2 * nfeat, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
    "\n",
    "        self.conv7a = dice(4 * nfeat,2 * nfeat,width = 128,height = 128)\n",
    "        self.bn7a = nn.BatchNorm2d(2 * nfeat)\n",
    "        self.conv7b = dice(2 * nfeat,2 * nfeat,width = 128,height = 128)\n",
    "        self.bn7b = nn.BatchNorm2d(2 * nfeat)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(in_channels = 2 * nfeat,out_channels = nfeat, kernel_size = (3,3), stride = 2, padding = 1, output_padding = 1)\n",
    "\n",
    "        self.conv8a = dice(2 * nfeat,nfeat,width = 256,height = 256)\n",
    "        self.bn8a = nn.BatchNorm2d(nfeat)\n",
    "        self.conv8b = dice(nfeat,nfeat,width = 256,height = 256)\n",
    "        self.bn8b = nn.BatchNorm2d(nfeat)\n",
    "\n",
    "        self.seg_map_conv = nn.Conv2d(in_channels = nfeat,out_channels = 1, kernel_size = (1,1))\n",
    "\n",
    "        self.aspp = aspp_dice(in_channels = 8 * nfeat,mid_channels = mid_channels,prev_dim = (32,32),rates = [2,4,6])\n",
    "\n",
    "    def forward(self,inp):\n",
    "        \n",
    "        \"\"\"\n",
    "            Method to perform the forward pass of KidneyNet\n",
    "            \n",
    "            Arguments:\n",
    "                inp   : Input tissue image to KidneyNet\n",
    "                \n",
    "            Returns  : \n",
    "                out   : The distance map of the corresponding tissue image\n",
    "        \"\"\"\n",
    "\n",
    "        out1 = nn.ReLU()(self.bn1a(self.conv1a(inp)))\n",
    "        out1 = nn.ReLU()(self.bn1b(self.conv1b(out1)))\n",
    "        out2 = self.maxpool1(out1)\n",
    "\n",
    "        out2 = nn.ReLU()(self.bn2a(self.conv2a(out2)))\n",
    "        out2 = nn.ReLU()(self.bn2b(self.conv2b(out2)))\n",
    "        out3 = self.maxpool2(out2)\n",
    "\n",
    "        out3 = nn.ReLU()(self.bn3a(self.conv3a(out3)))\n",
    "        out3 = nn.ReLU()(self.bn3b(self.conv3b(out3)))\n",
    "        out4 = self.maxpool3(out3)\n",
    "\n",
    "        out4 = nn.ReLU()(self.bn4a(self.conv4a(out4)))\n",
    "        out4 = nn.ReLU()(self.bn4b(self.conv4b(out4)))\n",
    "        \n",
    "        out_aspp = self.aspp(out4)\n",
    "\n",
    "        out6 = self.upconv1(out_aspp)\n",
    "\n",
    "        out6 = tor.cat((out6,out3),dim = 1)\n",
    "        del out4\n",
    "\n",
    "        out6 = nn.ReLU()(self.bn6a(self.conv6a(out6)))\n",
    "        out6 = nn.ReLU()(self.bn6b(self.conv6b(out6)))\n",
    "        out7 = self.upconv2(out6)\n",
    "\n",
    "        out7 = tor.cat((out7,out2),dim = 1)\n",
    "        del out3\n",
    "        del out6\n",
    "\n",
    "        out7 = nn.ReLU()(self.bn7a(self.conv7a(out7)))\n",
    "        out7 = nn.ReLU()(self.bn7b(self.conv7b(out7)))\n",
    "        out8 = self.upconv3(out7)\n",
    "\n",
    "        out8 = tor.cat((out8,out1),dim = 1)\n",
    "        del out2\n",
    "        del out7\n",
    "\n",
    "        out8 = nn.ReLU()(self.bn8a(self.conv8a(out8)))\n",
    "        out8 = nn.ReLU()(self.bn8b(self.conv8b(out8)))\n",
    "        \n",
    "        out = nn.ReLU()(self.seg_map_conv(out8))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a587dYCi5-Yv"
   },
   "outputs": [],
   "source": [
    "def get_f1(gt,pred):\n",
    "\n",
    "    \"\"\"\n",
    "        Method to find the mean f1 score given a batch of segmentation predictions and ground truth segmentation images\n",
    "    \n",
    "        Arguments:\n",
    "            gt   : Ground truth segmentation images\n",
    "            pred : Predicted segmentation images\n",
    "            \n",
    "        Returns  :\n",
    "            Mean f1 score of the given batch of predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    f1 = []\n",
    "    m = gt.shape[0]\n",
    "\n",
    "    if(not isinstance(gt,np.ndarray)):\n",
    "        gt = gt.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    if(not isinstance(pred,np.ndarray)):\n",
    "        pred = pred.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    for predicted,ground_truth in zip(pred,gt):\n",
    "        predicted = ((predicted - predicted.min()) / (predicted.max() - predicted.min())) * 1\n",
    "        predicted = np.uint8(predicted)\n",
    "\n",
    "        ground_truth = ((ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min())) * 1\n",
    "        ground_truth = np.uint8(ground_truth)\n",
    "\n",
    "        predicted = predicted.flatten()\n",
    "        ground_truth = ground_truth.flatten()\n",
    "\n",
    "        predicted = np.uint8(predicted)\n",
    "        ground_truth = np.uint8(ground_truth)\n",
    "\n",
    "        f1.append(f1_score(ground_truth,predicted))\n",
    "\n",
    "    return np.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n766dr_n6t72"
   },
   "outputs": [],
   "source": [
    "def get_ji(gt,pred):\n",
    "    \n",
    "    \"\"\"\n",
    "        Method to find the mean jaccard index given a batch of segmentation predictions and ground truth segmentation images\n",
    "    \n",
    "        Arguments:\n",
    "            gt   : Ground truth segmentation images\n",
    "            pred : Predicted segmentation images\n",
    "            \n",
    "        Returns  :\n",
    "            Mean jaccard index of the given batch of predictions\n",
    "    \"\"\"\n",
    "\n",
    "    ji = []\n",
    "    m = gt.shape[0]\n",
    "\n",
    "    if(not isinstance(gt,np.ndarray)):\n",
    "        gt = gt.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    if(not isinstance(pred,np.ndarray)):\n",
    "        pred = pred.detach().cpu().numpy().squeeze()\n",
    "\n",
    "    for predicted,ground_truth in zip(pred,gt):\n",
    "        predicted = ((predicted - predicted.min()) / (predicted.max() - predicted.min())) * 1\n",
    "        predicted = np.uint8(predicted)\n",
    "\n",
    "        ground_truth = ((ground_truth - ground_truth.min()) / (ground_truth.max() - ground_truth.min())) * 1\n",
    "        ground_truth = np.uint8(ground_truth)\n",
    "\n",
    "        predicted = predicted.flatten()\n",
    "        ground_truth = ground_truth.flatten()\n",
    "\n",
    "        predicted = np.uint8(predicted)\n",
    "        ground_truth = np.uint8(ground_truth)\n",
    "\n",
    "        ji.append(jaccard_score(ground_truth,predicted))\n",
    "\n",
    "    return np.mean(ji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3ugJxTC6FxBd"
   },
   "outputs": [],
   "source": [
    "## Initializing the elastic transform method\n",
    "\n",
    "elastic = A.Compose([\n",
    "        A.ElasticTransform(alpha = 1)\n",
    "    ],\n",
    "    additional_targets={\"mask2\" : \"mask\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YvPuRxB5D99s"
   },
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "        Module that implements dataset related utilities\n",
    "    \"\"\"\n",
    "    \n",
    "    total_mean = 0\n",
    "\n",
    "    def __init__(self,files_dir,data_size = -1,phase = \"\",apply_transforms = True):\n",
    "        \n",
    "        \"\"\"\n",
    "            Constructor that initializes the dataset class instance\n",
    "            \n",
    "            Arguments: \n",
    "                files_dir        : Directory where the dataset is placed\n",
    "                data_size        : The number of data samples in the dataset\n",
    "                phase            : Training / validation / testing\n",
    "                apply_transforms : flag to toggle applying data augmentation related transforms\n",
    "        \"\"\"\n",
    "\n",
    "        data_dir = os.path.join(files_dir,\"data\")\n",
    "        gt_dir = os.path.join(files_dir,\"gts\")\n",
    "\n",
    "        files = os.listdir(gt_dir)\n",
    "    \n",
    "        data_files = [os.path.join(data_dir,x) for x in files]\n",
    "        gt_files = [os.path.join(gt_dir,x) for x in files]\n",
    "\n",
    "        if(data_size == -1):\n",
    "            data_size = len(data_files)\n",
    "\n",
    "        self.data_files = data_files\n",
    "        self.gt_files = gt_files\n",
    "        self.data_size = data_size\n",
    "        self.apply_transforms = apply_transforms\n",
    "\n",
    "        if(phase == \"train\"):\n",
    "          dataset.total_mean = tor.from_numpy(calc_total_mean(self.data_files))\n",
    "          dataset.total_mean = dataset.total_mean.permute(2,0,1)\n",
    "          \n",
    "        print(\"shape of dataset.total_mean: \",dataset.total_mean.size())\n",
    "\n",
    "        del data_files\n",
    "        del gt_files\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        \"\"\"\n",
    "            Method to return the dataset size\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.data_size\n",
    "\n",
    "    def transforms(self,data,label,gt):\n",
    "        \n",
    "        \"\"\"\n",
    "            Method to apply transformations on the input image for data augmentation\n",
    "            \n",
    "            Arguments: \n",
    "                data  : The tissue image\n",
    "                label : The corresponding ground truth distance map\n",
    "                gt    : The ground truth segementation image\n",
    "                \n",
    "            Returns  : \n",
    "                data,label,gt after data augmentations through transormations\n",
    "        \"\"\"\n",
    "\n",
    "        ## Random Crop\n",
    "        i, j, h, w = transforms.RandomCrop.get_params(\n",
    "            data, output_size=(256,256))\n",
    "        data = TF.crop(data, i, j, h, w)\n",
    "        label = TF.crop(label, i, j, h, w)\n",
    "        gt = TF.crop(gt,i,j,h,w)\n",
    "\n",
    "        ## Random horizontal flip\n",
    "        if(random.random() > 0.5):\n",
    "            data = TF.hflip(data)\n",
    "            label = TF.hflip(label)\n",
    "            gt = TF.hflip(gt)\n",
    "\n",
    "        ## Random Vertical Flip\n",
    "        if(random.random() > 0.5):\n",
    "            data = TF.vflip(data)\n",
    "            label = TF.vflip(label)\n",
    "            gt = TF.vflip(gt)\n",
    "\n",
    "        ## Random rotate in multiples of 90\n",
    "        range_of_angles = [0,90,180,270]\n",
    "        angle = random.choice(range_of_angles)\n",
    "        data = TF.rotate(data,angle)\n",
    "        label = TF.rotate(label,angle,fill = (0,))\n",
    "        gt = TF.rotate(gt,angle,fill = (0,))\n",
    "        \n",
    "        ## Applying color-jitter to data\n",
    "        data = transforms.ColorJitter(brightness=0.3, contrast=0.3)(data)\n",
    "\n",
    "        return data,label,gt\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        \"\"\"\n",
    "            Method to obtain a triad of data,label,gt after pre-processing\n",
    "            \n",
    "            Arguments:\n",
    "                idx  : The index of the sample from the dataset\n",
    "                \n",
    "            Returns  : \n",
    "                The triad data,label,gt\n",
    "        \"\"\"\n",
    "        \n",
    "        data = self.data_files[idx]\n",
    "        label = self.label_files[idx]\n",
    "        gt = self.gt_files[idx]\n",
    "\n",
    "        data = im.open(data)\n",
    "        gt = cv2.imread(gt,0)\n",
    "        \n",
    "        ## Dynamic transformation of distance map\n",
    "        label = ndimage.distance_transform_edt(gt)\n",
    "        \n",
    "        gt = im.fromarray(gt)\n",
    "        label = im.fromarray(label)\n",
    "\n",
    "        if(self.apply_transforms):\n",
    "          data,label,gt = self.transforms(data,label,gt)\n",
    "        else:\n",
    "          data = data.resize((256,256))\n",
    "          label = label.resize((256,256))\n",
    "          gt = gt.resize((256,256))\n",
    "\n",
    "\n",
    "        if(self.apply_transforms):\n",
    "\n",
    "            data = np.array(data).reshape(data.size[0], data.size[1], -1)[:,:,:3]\n",
    "            label = np.array(label).reshape(label.size[0], label.size[1])\n",
    "            gt = np.array(gt).reshape(gt.size[0], gt.size[1])\n",
    "\n",
    "            result = elastic(image = data,mask = gt,mask2 = label)\n",
    "\n",
    "            data = result[\"image\"]\n",
    "            label = result[\"mask2\"]\n",
    "            gt = result[\"mask\"]\n",
    "\n",
    "        ## Convert PILs to tensors\n",
    "        data = transforms.ToTensor()(data)[:3,:,:]\n",
    "        label = transforms.ToTensor()(label)\n",
    "        gt = transforms.ToTensor()(gt)\n",
    "\n",
    "        label = label.type(tor.FloatTensor)\n",
    "        gt = gt.type(tor.LongTensor)\n",
    "        \n",
    "        data = ((data - data.min()) / (data.max() - data.min())) * 255\n",
    "        label = ((label - label.min()) / (label.max() - label.min())) * 255\n",
    "\n",
    "        ## subtracting the mean\n",
    "        data = data - dataset.total_mean\n",
    "\n",
    "        return data,label,gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qMrGzaQYUhcu",
    "outputId": "b4bc5506-615a-4a74-bf53-8593c25ba19f"
   },
   "outputs": [],
   "source": [
    "train_dir = \"./dataset_dir/train/\"\n",
    "\n",
    "trainset = dataset(files_dir = train_dir,phase = \"train\",apply_transforms=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,batch_size = 8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zpLHL2Im1vb8",
    "outputId": "fcb138f7-bf25-486f-af38-9a3a5ee5339d"
   },
   "outputs": [],
   "source": [
    "val_dir = \"./dataset_dir/val\"\n",
    "\n",
    "valset = dataset(files_dir=val_dir,apply_transforms=False)\n",
    "valloader = torch.utils.data.DataLoader(valset,batch_size=8,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRiSXfkiSsUE"
   },
   "outputs": [],
   "source": [
    "def get_segments(distmaps,param = 7,thresh1 = 0.5,thresh2 = 5):\n",
    "\n",
    "    \"\"\"\n",
    "        Method to perform post-processing on a batch of distance map predictions\n",
    "        \n",
    "        Arguments:\n",
    "            distmaps  : Predictions of distance maps\n",
    "            param     : parameters to for post processing\n",
    "            thresh1   : th2\n",
    "            thresh2   : th1\n",
    "    \"\"\"\n",
    "    \n",
    "    segments = []\n",
    "\n",
    "    for res in distmaps:\n",
    "\n",
    "        if(not isinstance(res,np.ndarray)):\n",
    "            res = res.detach().cpu().numpy().squeeze()\n",
    "            \n",
    "        res = ((res - res.min()) / (res.max() - res.min())) * 255\n",
    "        res = np.uint8(res)\n",
    "        res[res<thresh2] = 0 \n",
    "\n",
    "        res = pp.PostProcess(res,param = param,thresh = thresh1)\n",
    "        res[res!=0] = 1\n",
    "\n",
    "        segments.append(res)\n",
    "\n",
    "    segments = np.array(segments)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XEijxmetwqQO"
   },
   "outputs": [],
   "source": [
    "def train(seg,epochs,dataloaders,hyper_params,reset = True,save = False):\n",
    "\n",
    "    \"\"\"\n",
    "        Method to perform training\n",
    "        \n",
    "        Arguments: \n",
    "            seg         : KidneyNet instance\n",
    "            epochs      : Total number of epochs to train\n",
    "            dataloaders : list of dataloaders\n",
    "            hyper_params: list of hyper-parameters\n",
    "            reset       : Flag that toggles the reset operation\n",
    "            save        : Flag that toggles the saving operation\n",
    "            \n",
    "        Returns:\n",
    "            epoch_losses: training history\n",
    "    \"\"\"\n",
    "    \n",
    "    trainloader,valloader = dataloaders\n",
    "\n",
    "    lr,reg,nfeat,postproc_params = hyper_params\n",
    "\n",
    "    if(postproc_params):\n",
    "      param,thresh1,thresh2 = postproc_params\n",
    "    else:\n",
    "      param = 7\n",
    "      thresh1 = 0.5\n",
    "      thresh2 = 20\n",
    "\n",
    "    if(reset):\n",
    "        del seg\n",
    "        seg = dist_dice(in_channels=3,nfeat = nfeat).to(device)\n",
    "        print(\"/////////////////// Weights have been reset \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(seg.parameters(),lr = lr,weight_decay = reg)\n",
    "\n",
    "    epoch_losses = []\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "      batch_losses = []\n",
    "      batch_f1 = []\n",
    "      batch_ji = []\n",
    "\n",
    "      for batch_idx,(data,label,gt) in enumerate(trainloader):\n",
    "\n",
    "          data,label = data.to(device),label.to(device)\n",
    "\n",
    "          optimizer.zero_grad()\n",
    "\n",
    "          out = seg(data) \n",
    "          loss = criterion(out,label)\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          segment_maps = get_segments(out,param = param,thresh1 = thresh1,thresh2 = thresh2)\n",
    "\n",
    "          batch_f1.append(get_f1(gt,segment_maps))\n",
    "          batch_ji.append(get_ji(gt,segment_maps))\n",
    "\n",
    "          batch_losses.append(loss.item())\n",
    "\n",
    "      epoch_losses.append(np.mean(batch_losses))\n",
    "\n",
    "      print(\"Epoch: \",epoch,\"\\tEpoch Loss: \",epoch_losses[-1],\"Mean f1: \",np.mean(batch_f1))\n",
    "      print(\"Mean ji: \",np.mean(batch_ji),\"HM: \",stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)]))\n",
    "\n",
    "      seg.eval()\n",
    "      with tor.no_grad():\n",
    "\n",
    "          batch_losses = []\n",
    "          batch_f1 = []\n",
    "          batch_ji = []\n",
    "\n",
    "          for batch_idx,(valdata,vallabel,valgt) in enumerate(valloader):\n",
    "\n",
    "              valdata,vallabel = valdata.to(device),vallabel.to(device)\n",
    "\n",
    "              valout = seg(valdata)\n",
    "              loss = criterion(valout,vallabel)\n",
    "\n",
    "              segment_maps = get_segments(valout,param = param,thresh1 = thresh1,thresh2 = thresh2)\n",
    "              batch_losses.append(loss.item())\n",
    "              batch_f1.append(get_f1(valgt,segment_maps))\n",
    "              batch_ji.append(get_ji(valgt,segment_maps))\n",
    "\n",
    "          print(\"Val Loss: \",np.mean(batch_losses),\"Mean f1: \",np.mean(batch_f1))\n",
    "          print(\"Mean ji: \",np.mean(batch_ji),\"HM: \",stats.harmonic_mean([np.mean(batch_f1),np.mean(batch_ji)]))\n",
    "\n",
    "\n",
    "      print(\"-------------------------------------------------------------------------\")\n",
    "      seg.train()\n",
    "\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7SoZeB1oIoLB",
    "outputId": "fd2d1452-f8d9-415c-9b28-fc4547d6a36f"
   },
   "outputs": [],
   "source": [
    "## setting up training\n",
    "\n",
    "device = tor.device(\"cuda:0\" if tor.cuda.is_available() else \"cpu\")\n",
    "print(\"using: \",device)\n",
    "\n",
    "nfeat = 64\n",
    "seg = dist_dice(in_channels=3,nfeat = nfeat).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7w3pKKYcI3Go",
    "outputId": "f859a335-d485-4129-ebd0-a3d8ce38a3b4"
   },
   "outputs": [],
   "source": [
    "## Training Loop\n",
    "\n",
    "epochs = 20\n",
    "nfeat = 64\n",
    "lr = 1e-3\n",
    "reg = 1e-3\n",
    "reset = True\n",
    "dataloaders = [trainloader,valloader]\n",
    "postproc_params = [7,0.5,28]\n",
    "hyper_params = [lr,reg,nfeat,postproc_params]\n",
    "\n",
    "_ = train(seg,epochs,dataloaders,hyper_params = hyper_params,reset = reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model after training\n",
    "\n",
    "model = seg.state_dict()\n",
    "\n",
    "tor.save(model,\"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "448TiuFMr2Xp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "DIST_dice_aspp_kidney.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
